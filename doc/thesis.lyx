#LyX 1.4.4 created this file. For more info see http://www.lyx.org/
\lyxformat 245
\begin_document
\begin_header
\textclass article
\language english
\inputencoding latin2
\fontscheme default
\graphics default
\paperfontsize default
\spacing single
\papersize default
\use_geometry false
\use_amsmath 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle default
\tracking_changes false
\output_changes false
\end_header

\begin_body

\begin_layout Title
Regression Testing For zlomekFS
\end_layout

\begin_layout Author
Jiri Zouhar
\end_layout

\begin_layout Abstract
Something very smart it is, young adept.
\end_layout

\begin_layout Abstract
\begin_inset LatexCommand \tableofcontents{}

\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Subsection
Motivation
\end_layout

\begin_layout Subsection
Goals
\end_layout

\begin_layout Standard
Extend the existing zlomekFS implementation by introducing a regression
 testing framework.
 The framework should be capable of submitting both predefined and random
 workload to the filesystem and, either by comparing the results with the
 same operations performed over another filesystem, or by some other appropriate
 means, identify filesystem errors.
 The identification of an error should contain both a minimal sequence of
 steps necessary to reproduce the error, and the debugging protocol excerpt
 relevant to the error.
 The framework should include support for generating the debugging protocol
 and changing the network conditions.
\end_layout

\begin_layout Standard
Make all the developer documentation an integral part of the zlomekFS project
 using appropriate tools such as DoxyGen.
\end_layout

\begin_layout Subsection
Structure of the Thesis
\end_layout

\begin_layout Section
Filesystem testing
\end_layout

\begin_layout Standard
Filesystem can be seen as many things and thus it can be tested from at
 least the same number points of view.
 
\end_layout

\begin_layout Paragraph
Specification testing
\end_layout

\begin_layout Standard
We could look on filesystem as on specification of way how to store data
 and associated metedata on storage media.
 In this case we can ask if the structures are sufficient for accessing
 stored data, if the specfication covers all eventual operations that should
 be availible and if the transistions are sane.
 Specification testing is done only once at the begining.
\end_layout

\begin_layout Paragraph
Api conformity
\end_layout

\begin_layout Standard
Some filesystems don't focus on the way how to store data on media but how
 to make them accessible.
 Well known group of such filesystems are network filesystems.
 They suppose that some other filesystem do the storage and they specify
 only the way how data will be accessible remotely and put some restrictions
 on the filesystem behaviour.
 In this case we test the particular implementations if they are conform
 to the specification.
 stabilni iface / protokol
\end_layout

\begin_layout Paragraph
Functional testing
\end_layout

\begin_layout Standard
implementation
\end_layout

\begin_layout Standard
Filesystems have many things in common with normal pieces of code such as
 server or desktop applications.
 But in the means of tesing there is big problem in simulating normal enviroment
 for filesystems.
 This is caused by their low level nature and could be one of key reasons
 why most of the test suites are designed as black box testing.
\end_layout

\begin_layout Standard
is the one we will be doing.
\end_layout

\begin_layout Standard
The most desired feature on testing framework is ease of use tightly coupled
 with automation.
 To achieve this, the tests have to be written in understandable format,
 close to the tested code.
 By the meaning of regression testing, they have to be runned automatically,
 in scheduled periods (defined by amouth of time or changes), the results
 must be collected and presented in readable format somewhere.
\end_layout

\begin_layout Standard
For tracing the code execution, there may be some tracing tools and logging
 tools.
 They have to have minimal footprint and collect as much information as
 possible.
 Their output must be formatted in way compatible with the automation framework
 and with the presentation tool too, if possible.
\end_layout

\begin_layout Standard
The output of tests could be accompanied with some state information from
 the time of failure.
 This can be achieved by using some snapshoting tool which may or may not
 support resuming.
 
\end_layout

\begin_layout Standard
For filesystem testing, it is hard to find good testing patterns, which
 will cover all cases, which can occur.
 So it is good idea to have some random workload generator, which can randomly
 exercise the filesystem.
 The problem with this approach is, that outputs of such testing tends to
 be very big and only a small portion of them is related to the occured
 error.
 To allow random testing and avoid the unwanted side efects, some pruning
 algorithm has to be used.
 The reruns of tests may use the snapshots, if the method used for snapshoting
 make the resume possible.
\end_layout

\begin_layout Standard
As the ZloFS is multi-threaded, distributed filesystem, the suite should
 have some support or at least extensibility to allow control or simulation
 of distributed enviroment.
\end_layout

\begin_layout Paragraph
Benchmarking
\end_layout

\begin_layout Standard
Are tests which should answer the question 
\begin_inset Quotes eld
\end_inset

how long it will take
\begin_inset Quotes erd
\end_inset

 for every operation we could do with filesystem.
 They measure the performance of specific implementation in conjunction
 with given setup assuming the implementation is sane and doesn't do any
 invalid shortcuts.
 Their goal is to compare more implementations or filesystems.
 This thesis won't consider this type of tests, because there is only one
 implementation of ZFS.
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Subsection
Format
\end_layout

\begin_layout Standard
When tests are expected to be executed manually, then the format could vary.
 On the other hand, when they have to be executed automatically, then for
 every format there must be support in all components of the test suite.
 Because of this there is tendency to minimize number of formats.
 
\end_layout

\begin_layout Standard
The basic choice is to write tests in native language of the application.
 Sometimes there is support for inlining tests to normal code with some
 flags saying 
\begin_inset Quotes eld
\end_inset

this is test code, it should be runned when testing
\begin_inset Quotes erd
\end_inset

.
 This allow tests as close to code as possible.
 It is ideal for short tests of functionality of separated parts (objects,
 libraries, etc).
 
\end_layout

\begin_layout Standard
For automated testing are often used scripting languages to write either
 control logic or whole thing including tests.
 Scripting languages are ideal for the logic because of their flexibility.
 The reason for writing tests in the same languate goo is that it could
 be easier integrated in that way.
\end_layout

\begin_layout Standard
Another possibility is to have tests in some proper format.
 This offer possibility of having the format very suitable for the needs
 of particular software, but this bring disadvantage of having to change
 the format every time a lag is found in specification or a new requirement
 is found.
\end_layout

\begin_layout Standard
Some testing tools uses configuration (tests) in xml or xml with embedded
 code.
 Main reason for using xml is option of using external tools for editing
 or xml-based transformation.
 On other hand, xml is very unsuitable format for hand written code and
 the DTD of configuration is often hard to understand too.
\end_layout

\begin_layout Standard
For component based systems is often used model checking or behaviour protocols.
 For this approach, there is some meta-language for defining actions and
 requirements of interfaces and some logic algebra to define states and
 conditions which must hold.
 It is usefull for checking the design of whole application, but there is
 speed issues when using behaviour protocols for checking larger or complex
 systems.
\end_layout

\begin_layout Subsection
Logging, tracing
\end_layout

\begin_layout Paragraph
Models
\end_layout

\begin_layout Standard
When an error is detected in software, developer needs to have as much informati
on about the failure as possible.
 What occured is nice to know but in most cases useless without without
 more details about the run.
 Therefore developers use logging and tracing to get some useful information
 about the particular run.
\end_layout

\begin_layout Standard
Tracing we mean storing information about call sequence in the program,
 by logging we mean saving information about data changes or notes about
 states of system inserted by developer.
 In most cases this features are provided by one tool.
\end_layout

\begin_layout Standard
The simpliest logging tool used is insertion of 
\series bold
direct message prints
\series default
.
 Printing may provide the information needed, but it suffer by not having
 centralized control of what has to be printed.
 This leads to excessive logging, in which is hard to find a usefull information
, and if we want to avoid this it force us to changing the code on many
 places.
\end_layout

\begin_layout Standard
So the next logical step is to send logging messages (accompanied by importance
 level) to some 
\series bold
centralized facility
\series default
.
 The importance levels are in most cases directly given in advance.
 Providing this it is possible to change the amount of information centraly
 and even redirect the messages to distinct places.
\end_layout

\begin_layout Standard
When simple distinguishment by importance is not enough then more advanced
 logging facilities comes with 
\series bold
tagging of messages
\series default
.
 Tags could be flat or of arbitrary structure.
 This allow better filtering of messages of special types.
 
\end_layout

\begin_layout Standard
Other approach to logging is to have more than one logger.
 In this case the tool has frequently 
\series bold
producer - consumer
\series default
 based architecture and loggers are organized to dynamically created hierarchy.
 This ease goal of having different output locations for different types
 of messages.
 On the other hand, the architecture is not so easy to understand for anybody
 who might contribute to the code.
 Moreover, with more people participating on development, it is nearly impossibl
e to keep the hierarchy of producers and consumers used in application sane.
 
\end_layout

\begin_layout Standard
The last approach to logging and tracing is called 
\series bold

\begin_inset Quotes eld
\end_inset

aspect oriented programing
\series default

\begin_inset Quotes erd
\end_inset

.
 In this case the logging is not present in code itself but it is separated
 as independent concern to aspect - logical definition what and where has
 to be logged.
 
\end_layout

\begin_layout Paragraph
Pitfalls
\end_layout

\begin_layout Standard
Even if a adequate logging facility is used to debug the software, there
 can arise problems when the facility is used under some automated stress
 testing.
 The amouth of output logs will eventually gets too big for storage capacity
 or at least for the potential reader to deal with.
 So the automation tool must be able to communicate with the logging facility
 and in some way dynamically change the amouth of output according to needs.
 This must be tuned so the biggest possible portion of unrelated logs is
 thrown away but the crucial information for debugging is preserved for
 failure as the failure could be hard to repeat.
\end_layout

\begin_layout Standard
There is one more reason that may be considered for muting logging output.
 The reason is that logging could slow the application down.
 To check how much logging slows down a ordinary application, some measurements
 were done.
 
\end_layout

\begin_layout Standard
For testing was used real application - session server from the SUCKS 
\begin_inset LatexCommand \cite{SUCKS}

\end_inset

project.
 The session server was threaded and accessible by network.
 Logging facility was simple centralized logger with pre-definet log levels.
 Logger was alternated so it measures time spent by logging.
 Tests consisted of pre-defined workload, output was time spent by whole
 application, time spent in logging and characters printed.
 Test cycle was composet of one run of all tests for every log level and
 log target.
 After finishing the cycle starts again.
 This had been running for approximately thirty hours on two platforms:
\end_layout

\begin_layout Enumerate
intel centrino with core2duo cpu set to static frequency of 1Ghz with 2GB
 memory (most unused) running kernel 2.6.20.1 x86_64.
 
\end_layout

\begin_layout Enumerate
motorola ppc MPC8241 (177 bogomips) with 128MB memory running kernel 2.4.32
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Standard
\begin_inset Graphics
	filename logSums.png
	width 100text%

\end_inset


\end_layout

\begin_layout Caption
Logging load
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Both platforms behaved equally, the only difference was in speed (we must
 consider, that motorola was connected by network and all console prints
 must went through ssh).
 From results we can see that all logging targets had the same footprint
 and the only 
\begin_inset Quotes eld
\end_inset

slow
\begin_inset Quotes erd
\end_inset

 target was console write.
 For non-blocking targets, the slowdown was in hundereths of per cent for
 all log levels and the difference between no logging and full logging was
 only one hundereth of per cent.
\end_layout

\begin_layout Standard
So when we don't need to read the output of application online we can log
 everything, having as target some circular buffer which can be flushed
 to file only when error occured.
 Filtering can be done afterwards by user.
 Another finding is that the logging footprint is in half made of checks
 if something has to be logged or not and to minimalize slowdown, logging
 must be entirely deleted in compile time.
 Problem with this is that it makes changes to code, thus to binary image
 too and this changes can lead to different behavior of erroneous code,
 so the bug could be unreproducible with different logging level.
\end_layout

\begin_layout Standard
Other problem which can arise with logging is that logging can act as synchroniz
ation primitive which could prevent some collisions to appear.
 Problem with synchronization can be solved by design of logging facility.
 The logger must be designed in way that create separated resources for
 every concurrently running entity in advance and then the only effect done
 by the logger is slowdown of creation of new 
\begin_inset Quotes eld
\end_inset

threads
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Subsection
Presentation layer
\end_layout

\begin_layout Standard
Usual test run produce outputs of many types, begining with standart outputs,
 going on with filesystem changes and debug logs and even including state
 snapshots, core dumps etc.
 These are data of very different types.
 The goal is to present them to user in usable way with structure that can
 be easilly understood and through ways which are accessible from as much
 enviroments as possible.
\end_layout

\begin_layout Paragraph
Raw data
\end_layout

\begin_layout Standard
The easiest way to present results is to leave them as they are produced
 by application and test suite.
 When this approach is used the raw data are often made vaailable for downloadin
g through simple protocol such as FTP or some remote access.
 Raw data hold always full information, don't suffer by ano losses from
 transformations.
 On the other hand raw data are often platform dependent and may have to
 be interpreted on the system that produced them.
 The data should be in standart format to allow readability by external
 tools.
\end_layout

\begin_layout Paragraph
Web interface
\end_layout

\begin_layout Standard
Dynamic web pages are nowadays very used way of presentation as they are
 relatively easy to write.
 Web pages have big advantage in accessibility - nearly every computer have
 web prowser installed and people are used to get information through these.
 On the other hand web pages can hardly display some debug outputs such
 as core dumps and other binary data.
 In this case data should be downloadable for reading through external tools.
 Interaction with web is little bit slower than with local application and
 user comfort is also worst.
\end_layout

\begin_layout Paragraph
Special application
\end_layout

\begin_layout Standard
Even raw data must be interpreted by application to be presented in readable
 form.
 When there aren't appropriate general tools, they should be written as
 part of test suite.
 The fact that they must be written is one big disadvantage by itself.
 Full featured interpreter of debug data with presentation layer may consist
 of the same amouth of work as test suite itself.
 Moreover requirements and dependencies of such application could be non-trivial
 and platform independency is hardly to achieve with this approach.
 The big pro of special application is that as written specially for a suite
 it should fits very well the needs.
\end_layout

\begin_layout Subsection
Random workload generation
\end_layout

\begin_layout Standard
must be generated from small test units (meta tests, atoms).
 Depending on subject tested atoms are either defined by tradition (basic
 operations that can be made on subject tested) or small well defined tests.
 It is sometimes wanted to group some atoms to create new (bigger) atom.
 In ideal case run of a beta test doesn't change state of subject tested.
 But this type of atoms can test only stateless sysatems and operations
 which are less errorneous and not so big candidates for regresion testing
 as statefull systems are.
 For statefull systems (and metat tests) there should be method how to define
 and check states and legal transistions.
 Simple method to allow this is to give to tester some way to define pre-
 and post- run hooks that can initialize state, check transistion and posibly
 do cleanup after test.
 While approach with pre and post run hooks is simple yet powerfull, there
 is one issue connected to it.
 In this system tester can use statefull tests but in trade of possible
 waste of resources.
 When test expected some state different that in which system is, it must
 either made a state change (non trivial operation out of test scope) or
 silently pass without testing and let the system run other test.
 More spohisticated system for resolving state-fullness is to give tester
 tool to define allowet transistions between tests.
 Transistions are often given by graph (edges can be allowed transistions
 or vice versa).
 
\end_layout

\begin_layout Standard
Sometimes it may be desirable to give some preferences (what should be tested).
 For random workload this means either binary switching tests on and off
 or giving preferences in percentage.
 When state-fullnes is not solved or solved by pre- and post- hooks, precentage
 is connected to tests.
 When transistions are used, precentage can be either for tests (implicit
 edges) or for transistions.
\end_layout

\begin_layout Standard
Length of continuous random workload can be simple defined as:
\end_layout

\begin_layout Itemize
number of tests (min, max, mean)
\end_layout

\begin_layout Itemize
time (resources) used
\end_layout

\begin_layout Itemize
by transistions to end point
\end_layout

\begin_layout Standard
When user preferences are given system itself is oten simple automata running
 on satatefull graph.
\end_layout

\begin_layout Subsection
Pruning output
\end_layout

\begin_layout Standard
When long test (or random test) fails we don't know which step has caused
 the failure, so we need test outputs (debugging info) to locate the bug.
 On the other hand output from long and random tests can be huge and most
 of it may be useless.
 The goal of pruning output is to provide enough information to find the
 bug and at the same time hide useless balast.
 Basically we can divide outputs to developer written log messages, system
 state snapshots (memory dums, FS state, etc).
 The second type is more resources consuming, but easy searchable by hand.
 So as storage capacity is cheap, we can simply leave all snapshots or limit
 space used by constant and delete old snapshots.
 As for logs the problem was described in chapter !!! logging !!!.
 When logging doesn't slow application down and doesn't change behaviour,
 the best approach is to log all, store all (or last X) and provide tool
 for filtering and searching logs.
 With this approach we can be sure that no crucial information was lost
 by heuristic prunning.
 In special cases lice low resource platforms (without storage, extremly
 slow, etc) where we can't afford wasting, some heuristic must be used.
 For system state this can be last state before recognizing failure and
 state after.
 For logs there can be more approaches which can be divided to 
\end_layout

\begin_layout Itemize
on-time prunning - test suite changes log level of application according
 to probability of failure.
 The question is, how it should know.
\end_layout

\begin_layout Itemize
afterwards - log level is constant for test run, logs are stored to cyclic
 buffer.
 When failure occurs, test suite will trim the buffer to store just usefull
 information.
\end_layout

\begin_layout Itemize
re-run - tests are runned with logging on minimal level.
 When failure occur, test suite will rerun the test with more logging 
\begin_inset Quotes eld
\end_inset

around
\begin_inset Quotes erd
\end_inset

 the failure, possibly skiping some parts of test (as for random generated
 workload).
\end_layout

\begin_layout Subsection
Checkpointing
\end_layout

\begin_layout Standard
As some failures are hardly reproducible, developer wants as much information
 about the faulty run as possible.
 Sometimes logs are not sufficient and state of application in time of failure
 is needed.
 That's why some snapshoting support might be usefull.
 
\end_layout

\begin_layout Standard
Moreover, as the runs to failure could be very long, the test suite may
 try to repeat just short parts of them or skip some steps to find the shortest
 possible run to bring about the bug.
 For reruns is best, when the second run has the same start conditions.
 The snapshots (checkopoints) can help with it by resuming from stored state
 (if possible).
\end_layout

\begin_layout Standard
There are many projects trying to create full featured checkpoint / resume
 support for applications.
 They can be divided in two groups: userspace only tools and kernel-based
 tools.
 The main problem among them is, that none of them have full support for
 every resource an application could use.
 The most frequently missing features are suspend / resume support for:
 networking, devices, threads, signal handlers, shm, shared objects.
 Some of them (BCLR 
\begin_inset LatexCommand \cite{BLCR}

\end_inset

, CryptoPID 
\begin_inset LatexCommand \cite{cryptoPID}

\end_inset

, Chpox 
\begin_inset LatexCommand \cite{chpox}

\end_inset

) seems to have everything needed, but for the price of many constraints
 and dependencies.
 
\end_layout

\begin_layout Standard
Other possibility, which solve the matter of sandboxing too is to use some
 virtualization tool and run application (not necessarilly test suite) inside
 virtual machine.
 Nowadays there is many virtualization tools with support for snapshoting
 (for ex.
 openVZ 
\begin_inset LatexCommand \cite{openVZ}

\end_inset

, Vmware 
\begin_inset LatexCommand \cite{Vmware}

\end_inset

, Xen 
\begin_inset LatexCommand \cite{Xen}

\end_inset

, Qemu 
\begin_inset LatexCommand \cite{Qemu}

\end_inset

).
 However, working with virtualization is fairly complicated and we can't
 test hardware dependent issues on them.
\end_layout

\begin_layout Standard
The last and easiest possibility is to use just snapshoting without resume
 and save the snapshots in some easy to read format.
 For this we can use for example GDB gcore 
\begin_inset LatexCommand \cite{gcore}

\end_inset

 command (which creates gdb core dumps) to pause and snapshot the application.
\end_layout

\begin_layout Subsection
Distributed testing
\end_layout

\begin_layout Subsection
Sandboxing
\end_layout

\begin_layout Subsection
Automation
\end_layout

\begin_layout Subsection
Filesystem test patterns
\end_layout

\begin_layout Paragraph
fstest
\end_layout

\begin_layout Paragraph
fsx
\end_layout

\begin_layout Paragraph
solaris
\end_layout

\begin_layout Paragraph
ltp
\end_layout

\begin_layout Section
The test suite architecture
\end_layout

\begin_layout Standard
python
\end_layout

\begin_layout Subsection
Used tools
\end_layout

\begin_layout Paragraph
Web result presentation
\end_layout

\begin_layout Paragraph
Logging
\end_layout

\begin_layout Standard
We need logger with this features:
\end_layout

\begin_layout Itemize
it can be controlled externally
\end_layout

\begin_layout Itemize
it has simple still full featured interface
\end_layout

\begin_layout Itemize
it has to have implementations in both languages in which is written test
 suite and zfs 
\end_layout

\begin_layout Itemize
the output has to be in parseable and user readable format
\end_layout

\begin_layout Standard
This enforces writing of own logger, which suits best the needs.
 From models, we can't use aspect oriented logging as there is no implementation
 of aspects for both languages (and moreover it will be big requirement
 for developers to use aspects).
 The producer-consumer model seems to be too complicated as there will be
 large and non-homogenous group of developers working on zlomek fs.
\end_layout

\begin_layout Standard
So the logger will be centralized, with some sort of tagging with fast evaluatio
n.
 The output will be redirectable to some sort of shared resource (shm, network
 socket) which can be used and controlled by test suite.
 The format of written log for failure could be readable by some GUI or
 web based reader such as Chainsaw 
\begin_inset LatexCommand \cite{Chainsaw}

\end_inset

.
\end_layout

\begin_layout Paragraph
Build bot
\end_layout

\begin_layout Paragraph
Documentation
\end_layout

\begin_layout Paragraph
Coding standard
\end_layout

\begin_layout Section
Implementation details
\end_layout

\begin_layout Subsection
Logging
\end_layout

\begin_layout Standard
32/64b binary flag pool, some pre-defined, rest user defined (statically),
 automatic adding of info such as thread id, file, function and line number,
 defined output format (what to include), default stdout, redirected to
 file, shm, network socket.
 support for configuration files
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
\begin_inset LatexCommand \bibtex[plain]{references}

\end_inset


\end_layout

\end_body
\end_document
